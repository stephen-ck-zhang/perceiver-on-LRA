# Perciever on LRA Benchmark

_This is the class project in New York University Machine Learning For Language Understanding class during 2022 Spring. All rights reserved._

_We are grateful to Professor [Samuel R. Bowman](https://cims.nyu.edu/~sbowman/)'s inspiration and suggestions._


The project implements and reproduces the **LRA Benchmark** (its paper can be accessed at: [https://arxiv.org/abs/2011.04006](https://arxiv.org/abs/2011.04006)) based on the code coming from here: [https://github.com/mlpen/Nystromformer](https://github.com/mlpen/Nystromformer).

In addition, the project implements the newly released efficient transformer, Perciever (its paper can be access at: [https://arxiv.org/abs/2103.03206](https://arxiv.org/abs/2103.03206)) using [HuggingFace interface](https://huggingface.co/docs/transformers/model_doc/perceiver) for Perciever. Our goal is to compare different efficient transformers for their abilities on handling long sequence data, and our paper can be accessed at: [click here](https://drive.google.com/file/d/1ScjeETTqjyDoM-cOC2-arJ6QKqZ3jcJ0/view?usp=sharing).

People who contribute this system: Gavin Yang (zy2091@nyu.edu), Stephen Zhang (cz1906@nyu.edu), David Guo (jg6109@nyu.edu)
